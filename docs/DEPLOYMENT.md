# –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é - Service4CT

## –û–±–∑–æ—Ä

–î–∞–Ω–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è Service4CT –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ, –≤–∫–ª—é—á–∞—è Docker, –ª–æ–∫–∞–ª—å–Ω—É—é —É—Å—Ç–∞–Ω–æ–≤–∫—É –∏ –æ–±–ª–∞—á–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã.

## üê≥ Docker —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

### –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Docker 20.10+
- Docker Compose 2.0+
- –ú–∏–Ω–∏–º—É–º 8GB RAM
- 10GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ

### –ë—ã—Å—Ç—Ä–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/evgenyevih/Service4CT.git
cd Service4CT

# –ó–∞–ø—É—Å–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
docker compose up inference
```

### –°–±–æ—Ä–∫–∞ –æ–±—Ä–∞–∑–∞

```bash
# –°–±–æ—Ä–∫–∞ Docker –æ–±—Ä–∞–∑–∞
docker build -t service4ct:latest .

# –ó–∞–ø—É—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker run -v $(pwd)/data:/app/data -v $(pwd)/weights:/app/weights service4ct:latest
```

### Docker Compose –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```yaml
# docker-compose.yml
version: '3.8'

services:
  inference:
    build: .
    container_name: ct-analysis-inference
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./configs:/app/configs
      - ./weights:/app/weights
    environment:
      - CUDA_VISIBLE_DEVICES=  # –û—Ç–∫–ª—é—á–µ–Ω–∏–µ GPU
      - PYTHONPATH=/app
    command: bash -lc "python -m src.main --mode infer --input_dir data/input_zips --output_path data/results/results.xlsx"
    restart: "no"
```

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

| –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è | –û–ø–∏—Å–∞–Ω–∏–µ | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é |
|------------|----------|--------------|
| `CUDA_VISIBLE_DEVICES` | GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ | `""` (CPU) |
| `PYTHONPATH` | Python –ø—É—Ç—å | `/app` |
| `LOG_LEVEL` | –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è | `INFO` |

## üñ•Ô∏è –õ–æ–∫–∞–ª—å–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

### –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **–û–°**: Linux (Ubuntu 20.04+), macOS, Windows 10+
- **Python**: 3.11+
- **RAM**: 8GB+ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 16GB)
- **–î–∏—Å–∫**: 10GB+ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
- **GPU**: NVIDIA —Å CUDA 12.9+ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞

#### 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```bash
git clone https://github.com/evgenyevih/Service4CT.git
cd Service4CT
```

#### 2. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –° –ø–æ–º–æ—â—å—é conda (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
conda create -n service4ct python=3.11
conda activate service4ct

# –ò–ª–∏ —Å –ø–æ–º–æ—â—å—é venv
python -m venv service4ct
source service4ct/bin/activate  # Linux/macOS
# service4ct\Scripts\activate  # Windows
```

#### 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt

# PyTorch —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129
```

#### 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

```bash
# –¢–µ—Å—Ç –∏–º–ø–æ—Ä—Ç–∞
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import pydicom; print('PyDICOM: OK')"

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
python -m pytest tests/
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

#### 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
mkdir -p data/{input_zips,results,training_data,workdir}
mkdir -p weights logs plots

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞
chmod +x scripts/*.sh
```

#### 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `configs/config.yaml`:

```yaml
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
inference:
  num_slices: 64
  window: [-1000, 400]
  normalize: true
  threshold: 0.5

training:
  batch_size: 16  # –£–º–µ–Ω—å—à–∏—Ç—å –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏
  lr: 1e-4
  epochs: 50
  early_stopping_patience: 10
```

### –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞

#### –ò–Ω—Ñ–µ—Ä–µ–Ω—Å

```bash
# –ß–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç
./scripts/infer.sh

# –ù–∞–ø—Ä—è–º—É—é
python -m src.main --mode infer --input_dir data/input_zips --output_path data/results/results.xlsx
```

#### –û–±—É—á–µ–Ω–∏–µ

```bash
# –ß–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç
./scripts/train.sh

# –ù–∞–ø—Ä—è–º—É—é
python -m src.main --mode train
```

## ‚òÅÔ∏è –û–±–ª–∞—á–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

### AWS EC2

#### 1. –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç–∞–Ω—Å–∞

```bash
# –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
Instance Type: g4dn.xlarge (GPU)
Storage: 50GB SSD
OS: Ubuntu 20.04 LTS
```

#### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Docker

```bash
# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
sudo apt update && sudo apt upgrade -y

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```

#### 3. –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫
git clone https://github.com/evgenyevih/Service4CT.git
cd Service4CT
docker compose up -d inference
```

### Google Cloud Platform

#### 1. –°–æ–∑–¥–∞–Ω–∏–µ VM

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç–∞–Ω—Å–∞
gcloud compute instances create service4ct \
  --zone=us-central1-a \
  --machine-type=n1-standard-4 \
  --accelerator=type=nvidia-tesla-t4,count=1 \
  --image-family=ubuntu-2004-lts \
  --image-project=ubuntu-os-cloud
```

#### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ CUDA

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ NVIDIA –¥—Ä–∞–π–≤–µ—Ä–æ–≤
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.9.0/local_installers/cuda-repo-ubuntu2004-12-9-local_12.9.0-545.23.08-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2004-12-9-local_12.9.0-545.23.08-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2004-12-9-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda
```

### Azure Container Instances

#### 1. –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã —Ä–µ—Å—É—Ä—Å–æ–≤
az group create --name service4ct-rg --location eastus

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
az container create \
  --resource-group service4ct-rg \
  --name service4ct \
  --image service4ct:latest \
  --cpu 2 \
  --memory 8 \
  --ports 8080
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

#### 1. GPU –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

```yaml
# configs/config.yaml
inference:
  num_slices: 64
  window: [-1000, 400]
  normalize: true
  threshold: 0.4965  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥

training:
  batch_size: 32     # –£–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è GPU
  lr: 1e-4
  epochs: 100
  early_stopping_patience: 20
```

#### 2. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤

```bash
# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU
nvidia-smi

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏
free -h

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥–∏—Å–∫–∞
df -h
```

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

#### 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤

```yaml
# configs/config.yaml
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/app.log"
  max_size: "10MB"
  backup_count: 5
```

#### 2. –†–æ—Ç–∞—Ü–∏—è –ª–æ–≥–æ–≤

```bash
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ logrotate
sudo nano /etc/logrotate.d/service4ct

# –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
/path/to/service4ct/logs/*.log {
    daily
    missingok
    rotate 7
    compress
    delaycompress
    notifempty
    create 644 user user
}
```

### –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

#### 1. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞
sudo useradd -r -s /bin/false service4ct

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞
sudo chown -R service4ct:service4ct /opt/service4ct
sudo chmod 755 /opt/service4ct
```

#### 2. Firewall –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

```bash
# UFW –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
sudo ufw allow 22    # SSH
sudo ufw allow 80   # HTTP (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å)
sudo ufw enable
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏

### Health Check

```python
# health_check.py
import os
import sys
sys.path.append('src')

def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞"""
    checks = {
        'model_exists': os.path.exists('weights/best_model.pth'),
        'config_exists': os.path.exists('configs/config.yaml'),
        'data_dir_exists': os.path.exists('data/input_zips'),
        'results_dir_writable': os.access('data/results', os.W_OK)
    }
    
    all_ok = all(checks.values())
    return all_ok, checks

if __name__ == "__main__":
    ok, checks = health_check()
    print(f"Health Check: {'PASS' if ok else 'FAIL'}")
    for check, status in checks.items():
        print(f"  {check}: {'‚úì' if status else '‚úó'}")
```

### –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```python
# metrics.py
import time
import psutil
import torch

def get_system_metrics():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
    return {
        'cpu_percent': psutil.cpu_percent(),
        'memory_percent': psutil.virtual_memory().percent,
        'disk_percent': psutil.disk_usage('/').percent,
        'gpu_available': torch.cuda.is_available(),
        'gpu_memory': torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
    }
```

## üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è

### CI/CD Pipeline (GitHub Actions)

```yaml
# .github/workflows/deploy.yml
name: Deploy Service4CT

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Build Docker image
        run: docker build -t service4ct:${{ github.sha }} .
      
      - name: Deploy to production
        run: |
          docker tag service4ct:${{ github.sha }} service4ct:latest
          docker-compose up -d inference
```

### Ansible Playbook

```yaml
# deploy.yml
- hosts: production
  become: yes
  tasks:
    - name: Install Docker
      apt:
        name: docker.io
        state: present
    
    - name: Install Docker Compose
      pip:
        name: docker-compose
        state: present
    
    - name: Clone repository
      git:
        repo: https://github.com/evgenyevih/Service4CT.git
        dest: /opt/service4ct
        version: main
    
    - name: Start service
      docker_compose:
        project_src: /opt/service4ct
        state: present
```

## üîç –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

#### 1. –û—à–∏–±–∫–∏ CUDA

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"

# –†–µ—à–µ–Ω–∏–µ: —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ PyTorch
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129
```

#### 2. –ù–µ—Ö–≤–∞—Ç–∫–∞ –ø–∞–º—è—Ç–∏

```bash
# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏
free -h
ps aux --sort=-%mem | head

# –†–µ—à–µ–Ω–∏–µ: —É–º–µ–Ω—å—à–µ–Ω–∏–µ batch_size –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
```

#### 3. –û—à–∏–±–∫–∏ DICOM

```python
# –ü—Ä–æ–≤–µ—Ä–∫–∞ DICOM —Ñ–∞–π–ª–æ–≤
import pydicom
try:
    ds = pydicom.dcmread("file.dcm")
    print("DICOM —Ñ–∞–π–ª –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ DICOM: {e}")
```

### –õ–æ–≥–∏ –∏ –æ—Ç–ª–∞–¥–∫–∞

```bash
# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤
tail -f logs/app.log

# –û—Ç–ª–∞–¥–∫–∞ Docker
docker logs ct-analysis-inference

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
docker ps -a
```

## üìà –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

```yaml
# docker-compose.scale.yml
version: '3.8'

services:
  inference:
    build: .
    scale: 3  # –ó–∞–ø—É—Å–∫ 3 —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    environment:
      - WORKER_ID=${WORKER_ID}
```

### –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

```yaml
# –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
deploy:
  resources:
    limits:
      cpus: '4'
      memory: 8G
    reservations:
      cpus: '2'
      memory: 4G
```

## üìã –ß–µ–∫-–ª–∏—Å—Ç —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è

### –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞

- [ ] –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã
- [ ] Docker —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ `weights/best_model.pth`
- [ ] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞
- [ ] –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã

### –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

- [ ] –ö–æ–¥ —Å–∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω
- [ ] –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
- [ ] –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å–æ–±—Ä–∞–Ω
- [ ] –°–µ—Ä–≤–∏—Å –∑–∞–ø—É—â–µ–Ω
- [ ] Health check –ø—Ä–æ–π–¥–µ–Ω

### –ü–æ—Å—Ç-—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

- [ ] –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ
- [ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–∫—Ç–∏–≤–µ–Ω
- [ ] –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞

---

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ**: –î–∞–Ω–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–æ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö. –í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–µ—Ç–æ–¥ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–∞—à–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã.
